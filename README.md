# ğŸ¬ VideoTranscriberPro

**VideoTranscriberPro** is a lightweight web application that allows users to upload video files and receive automatic transcriptions using OpenAI's Whisper model. With a sleek frontend, Whisper-powered backend, and support for multiple file formats, itâ€™s the perfect tool for fast, high-quality video transcription.

![screenshot](https://your-screenshot-url-if-available)

---

## ğŸš€ Features

- ğŸ¥ Upload multiple videos at once (drag & drop interface)
- ğŸ§  Automatic transcription with OpenAI Whisper
- ğŸ“ Output with and without timestamps
- ğŸŒ Downloadable SRT subtitle support
- ğŸ“ Local file handling for privacy and performance
- ğŸ¨ Clean, responsive frontend UI (HTML/CSS/JS)
- ğŸ§ª Optional English translation support (when configured)

---

## ğŸ—‚ Project Structure

VideoTranscriberPro/

â”œâ”€â”€ app.py # Flask backend

â”œâ”€â”€ requirements.txt # Python dependencies

â”œâ”€â”€ templates/

â”‚ â””â”€â”€ index.html # Frontend UI

â”œâ”€â”€ static/

â”‚ â”œâ”€â”€ style.css # Styles

â”‚ â””â”€â”€ script.js # Frontend logic

â”œâ”€â”€ uploads/ # Temporary video uploads

â””â”€â”€ output/ # Transcription results

yaml
Copy
Edit

---

## âš™ï¸ Installation & Setup

### 1. Prerequisites

- **Python 3.8+**
- **FFmpeg** installed and available in your system's PATH

```bash
# Windows: Add FFmpeg to PATH after downloading from https://ffmpeg.org
# macOS:   brew install ffmpeg
# Ubuntu:  sudo apt-get install ffmpeg
2. Installation Steps
bash
Copy
Edit
# Clone the repository
git clone git@github.com:mobius29er/VideoTranscriberPro.git
cd VideoTranscriberPro

# (Recommended) Create a virtual environment
python -m venv venv
# Activate (Windows)
venv\Scripts\activate
# Activate (macOS/Linux)
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Run the Flask app
python app.py
Open your browser to http://localhost:5000

```

ğŸ§ª Usage
- Open the web app
- Drag & drop or select one or more videos
- Click Start Transcription
- Wait for processing (progress bar shows status)
- Download the result (with or without timestamps, SRT) (File will autogenerate also in the output folder for with, without, .srt. language, etc.)

ğŸ“„ Output Files
For each uploaded video, youâ€™ll get:

- âœ… video_transcript.txt â€“ raw transcript (no timestamps)
- âœ… video_with_timestamps.txt â€“ readable transcript with [HH:MM:SS - HH:MM:SS] markers
- âœ… video.srt â€“ subtitle file
- âœ… (Optional) English translation .txt and .srt if translation is enabled

ğŸ§  Whisper Model Options
Whisper supports several models:

Model	Size	Speed	Accuracy
tiny	~39 MB	Very Fast	Low
base	~74 MB	Fast	Moderate
small	~244 MB	Medium	Good
medium	~769 MB	Slower	Very Good
large	~1550 MB	Slowest	Best

To change the model, edit app.py:
```
model = whisper.load_model("medium")  # or "small", "large", etc.
ğŸ›  Configuration
UPLOAD_FOLDER and OUTPUT_FOLDER: Can be changed in app.py

MAX_CONTENT_LENGTH: Controls max upload size (default: 500MB)

ALLOWED_EXTENSIONS: Adjust to accept more/less video types

Translations: Can be enabled if you add a translation module or flag
```

ğŸ§¾ Example Output (with timestamps)

```
Copy
Edit
[00:00:00 - 00:00:05] Welcome to our demo on AI-powered transcription.
[00:00:05 - 00:00:10] In this video, weâ€™ll explore how Whisper works.
```


ğŸ’» Tech Stack
- Flask â€“ lightweight Python web framework
- Whisper â€“ OpenAI speech recognition model
- JavaScript/CSS â€“ frontend interactivity and styling
- FFmpeg â€“ video to audio conversion tool


ğŸ“¦ Requirements
```
txt
Copy
Edit
Flask==3.0.0
openai-whisper
torch
werkzeug==3.0.1
numpy<2
Install via:

bash
Copy
Edit
pip install -r requirements.txt
```

ğŸ“Œ Notes
- First-time run will auto-download the Whisper model
- FFmpeg must be correctly installed for audio extraction to work
- Your machine must support the chosen Whisper model (larger models require more memory)

ğŸ“£ Future Features (Planned)
- âœ… Language detection & translation toggle
- âœ… SRT subtitle preview in browser
- â³ GPU support via PyTorch CUDA if available
- â³ User authentication (multi-user support)
- â³ Cloud deployment template (Render, Vercel, Heroku)

ğŸ¤ Contributing

Contributions are welcome!

Please open an issue or submit a PR with any enhancements, fixes, or ideas.

ğŸ“œ License

This project is licensed under the MIT License.

ğŸ‘¤ Author

Jeremy Foxx
